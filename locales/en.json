{
  "app": {
    "name": "Open-LLM-VTuber",
    "description": "Low-latency voice-based LLM interaction tool",
    "version": "Version"
  },
  "server": {
    "starting": "Starting Open-LLM-VTuber server...",
    "started": "Server started successfully",
    "stopping": "Stopping server...",
    "error": "Server error occurred",
    "port_in_use": "Port {port} is already in use",
    "host": "Server host address",
    "port": "Server port number",
    "websocket_connected": "WebSocket client connected",
    "websocket_disconnected": "WebSocket client disconnected",
    "websocket_error": "WebSocket error occurred",
    "proxy_enabled": "Proxy mode enabled - /proxy-ws endpoint will be available",
    "initializing_context": "Initializing server context...",
    "context_initialized": "Server context initialized successfully.",
    "context_init_failed": "Failed to initialize server context: {error}",
    "starting_on": "Starting server on {host}:{port}"
  },
  "config": {
    "loading": "Loading configuration...",
    "loaded": "Configuration loaded successfully",
    "error": "Configuration loading error",
    "not_found": "Configuration file not found",
    "invalid": "Invalid configuration",
    "backup_created": "Configuration backup created",
    "backup_restored": "Configuration backup restored",
    "validation_error": "Configuration validation error",
    "field_required": "Field '{field}' is required",
    "invalid_value": "Field '{field}' has invalid value",
    "conf_version": "Configuration version",
    "host": "Server host address",
    "port": "Server port number",
    "config_alts_dir": "Directory for alternative configurations",
    "config_alt": "Alternative configuration to use",
    "enable_proxy": "Enable proxy mode for WebSocket connections",
    "tool_prompts": "Tool prompts that will be added to the character prompt",
    "character": {
      "conf_name": "Name of the character configuration file",
      "conf_uid": "Unique identifier of character configuration",
      "live2d_model_name": "Name of Live2D model",
      "character_name": "Name of the character",
      "persona_prompt": "Persona prompt for the character",
      "agent_config": "Agent configuration",
      "asr_config": "ASR configuration",
      "tts_config": "TTS configuration",
      "vad_config": "VAD configuration",
      "live2d_config": "Live2D configuration",
      "tts_preprocessor_config": "TTS preprocessor configuration",
      "human_name": "Name of the human user",
      "avatar": "Avatar image for the character"
    },
    "llm": {
      "interrupt_method": "Method to interrupt the LLM. Use 'system' if the provider supports inserting system prompts anywhere in chat memory, otherwise use 'user'.",
      "base_url": "Base URL for the API endpoint",
      "llm_api_key": "API key for authentication",
      "organization_id": "Organization ID for the API (Optional)",
      "project_id": "Project ID for the API (Optional)",
      "model": "Name of the LLM model to use",
      "temperature": "What sampling temperature to use, between 0 and 2.",
      "ollama": {
        "llm_api_key": "API key for authentication (defaults to 'default_api_key' for Ollama)",
        "keep_alive": "Keep the model loaded for this many seconds after the last request. Set to -1 to keep the model loaded indefinitely.",
        "unload_at_exit": "Unload the model when the program exits.",
        "use_harmony": "Use OpenAI Harmony format for gpt-oss models. This enables structured responses and function calls.",
        "top_p": "Top-p sampling parameter (0.0 to 1.0)",
        "max_tokens": "Maximum number of tokens to generate"
      },
      "lmstudio": {
        "llm_api_key": "API key for authentication (defaults to 'default_api_key' for LM Studio)",
        "base_url": "Base URL for LM Studio API (defaults to 'http://localhost:1234/v1')",
        "use_harmony": "Use OpenAI Harmony format for gpt-oss models. This enables structured responses and function calls.",
        "max_tokens": "Maximum number of tokens to generate",
        "stream": "Enable streaming responses"
      },
      "claude": {
        "base_url": "Base URL for Claude API",
        "llm_api_key": "API key for authentication",
        "model": "Name of the Claude model to use"
      },
      "llama": {
        "model_path": "Path to the GGUF model file",
        "verbose": "Enable verbose logging"
      },
      "providers": {
        "stateless_llm_with_template": "Stateless LLM with Template",
        "openai_compatible_llm": "Configuration for OpenAI-compatible LLM providers",
        "ollama_llm": "Configuration for Ollama",
        "lmstudio_llm": "Configuration for LM Studio",
        "openai_llm": "Configuration for Official OpenAI API",
        "gemini_llm": "Configuration for Gemini API",
        "mistral_llm": "Configuration for Mistral API",
        "zhipu_llm": "Configuration for Zhipu API",
        "deepseek_llm": "Configuration for Deepseek API",
        "groq_llm": "Configuration for Groq API",
        "claude_llm": "Configuration for Claude API",
        "llama_cpp_llm": "Configuration for local Llama.cpp"
      }
    },
    "asr": {
      "asr_model": "Speech-to-text model to use",
      "azure_asr": "Configuration for Azure ASR",
      "faster_whisper": "Configuration for Faster Whisper",
      "whisper_cpp": "Configuration for WhisperCPP",
      "whisper": "Configuration for Whisper",
      "fun_asr": "Configuration for FunASR",
      "groq_whisper_asr": "Configuration for Groq Whisper ASR",
      "sherpa_onnx_asr": "Configuration for Sherpa Onnx ASR",
      "azure": {
        "api_key": "API key for Azure ASR service",
        "region": "Azure region (e.g., eastus)",
        "languages": "List of languages to detect (e.g., ['en-US', 'zh-CN'])"
      },
      "faster_whisper": {
        "model_path": "Path to the Faster Whisper model",
        "download_root": "Root directory for downloading models",
        "language": "Language code (e.g., en, zh) or empty string for auto-detect",
        "device": "Device to use for inference (cpu, cuda, or auto)",
        "compute_type": "Compute type for the model (int8, float16, or float32)",
        "prompt": "Prompt for the model"
      },
      "whisper_cpp": {
        "model_name": "Name of the Whisper model",
        "model_dir": "Directory containing Whisper models",
        "print_realtime": "Print output in real-time",
        "print_progress": "Print progress information",
        "language": "Language code (e.g., auto, en, zh)",
        "prompt": "Prompt for the model"
      },
      "whisper": {
        "name": "Name of the Whisper model",
        "download_root": "Root directory for downloading models",
        "device": "Device to use for inference (cpu or cuda)",
        "prompt": "Prompt for the model"
      },
      "funasr": {
        "model_name": "Name of the FunASR model",
        "vad_model": "Voice Activity Detection model",
        "punc_model": "Punctuation model",
        "device": "Device to use for inference (cpu or cuda)",
        "disable_update": "Disable checking for FunASR updates on launch",
        "ncpu": "Number of CPU threads for internal operations",
        "hub": "Model hub to use (ms for ModelScope, hf for Hugging Face)",
        "use_itn": "Enable inverse text normalization",
        "language": "Language code (e.g., auto, zh, en)"
      },
      "groq": {
        "api_key": "API key for Groq Whisper ASR",
        "model": "Name of the Groq Whisper model to use",
        "lang": "Language code (leave empty for auto-detect)"
      },
      "sherpa_onnx": {
        "model_type": "Type of ASR model to use",
        "encoder": "Path to encoder model (for transducer)",
        "decoder": "Path to decoder model (for transducer)",
        "joiner": "Path to joiner model (for transducer)",
        "paraformer": "Path to paraformer model",
        "nemo_ctc": "Path to NeMo CTC model",
        "wenet_ctc": "Path to WeNet CTC model",
        "tdnn_model": "Path to TDNN model",
        "whisper_encoder": "Path to Whisper encoder model",
        "whisper_decoder": "Path to Whisper decoder model",
        "sense_voice": "Path to SenseVoice model",
        "tokens": "Path to tokens file",
        "num_threads": "Number of threads to use",
        "use_itn": "Enable inverse text normalization",
        "provider": "Provider for inference (cpu or cuda) (cuda option needs additional settings. Please check our docs)"
      }
    }
  },
  "llm": {
    "loading": "Loading LLM...",
    "loaded": "LLM loaded successfully",
    "error": "LLM loading error",
    "generating": "Generating response...",
    "generated": "Response generated",
    "interrupted": "Generation interrupted",
    "timeout": "Generation timeout",
    "invalid_response": "Invalid response format",
    "api_error": "API error occurred",
    "rate_limit": "Rate limit exceeded",
    "quota_exceeded": "Quota exceeded",
    "model_not_found": "Model not found",
    "authentication_failed": "Authentication failed",
    "network_error": "Network error occurred"
  },
  "asr": {
    "loading": "Loading ASR...",
    "loaded": "ASR loaded successfully",
    "error": "ASR loading error",
    "listening": "Listening for speech...",
    "transcribing": "Transcribing speech...",
    "transcribed": "Speech transcribed",
    "no_speech": "No speech detected",
    "timeout": "ASR timeout",
    "model_error": "ASR model error",
    "audio_error": "Audio processing error",
    "language_detected": "Language detected: {language}",
    "confidence": "Confidence: {confidence}",
    "duration": "Duration: {duration}s"
  },
  "tts": {
    "loading": "Loading TTS...",
    "loaded": "TTS loaded successfully",
    "error": "TTS loading error",
    "generating": "Generating speech...",
    "generated": "Speech generated",
    "synthesizing": "Synthesizing audio...",
    "synthesized": "Audio synthesized",
    "model_error": "TTS model error",
    "audio_error": "Audio generation error",
    "voice_not_found": "Voice not found",
    "text_too_long": "Text too long for synthesis",
    "rate_limit": "TTS rate limit exceeded"
  },
  "vad": {
    "loading": "Loading VAD...",
    "loaded": "VAD loaded successfully",
    "error": "VAD loading error",
    "speech_detected": "Speech detected",
    "speech_ended": "Speech ended",
    "no_speech": "No speech detected",
    "threshold": "VAD threshold: {threshold}",
    "sensitivity": "VAD sensitivity: {sensitivity}"
  },
  "live2d": {
    "loading": "Loading Live2D...",
    "loaded": "Live2D loaded successfully",
    "error": "Live2D loading error",
    "model_not_found": "Live2D model not found",
    "motion_playing": "Playing motion: {motion}",
    "expression_set": "Expression set: {expression}",
    "parameter_updated": "Parameter updated: {parameter}",
    "render_error": "Live2D render error",
    "model_information_loaded": "Model Information Loaded."
  },
  "proxy": {
    "connected": "Proxy client connected",
    "disconnected": "Proxy client disconnected",
    "message_received": "Message received from proxy",
    "message_sent": "Message sent to proxy",
    "error": "Proxy error occurred",
    "authentication_failed": "Proxy authentication failed",
    "rate_limit": "Proxy rate limit exceeded"
  },
  "twitch": {
    "connected": "Connected to Twitch",
    "disconnected": "Disconnected from Twitch",
    "message_received": "Message received from {user}: {message}",
    "chat_joined": "Joined chat: {channel}",
    "chat_left": "Left chat: {channel}",
    "error": "Twitch error occurred",
    "authentication_failed": "Twitch authentication failed",
    "rate_limit": "Twitch rate limit exceeded",
    "channel_not_found": "Channel not found: {channel}"
  },
  "memory": {
    "loading": "Loading memory...",
    "loaded": "Memory loaded successfully",
    "error": "Memory loading error",
    "saved": "Memory saved",
    "cleared": "Memory cleared",
    "exported": "Memory exported",
    "imported": "Memory imported",
    "corrupted": "Memory file corrupted",
    "not_found": "Memory file not found"
  },
  "tools": {
    "loading": "Loading tools...",
    "loaded": "Tools loaded successfully",
    "error": "Tools loading error",
    "executing": "Executing tool: {tool}",
    "executed": "Tool executed: {tool}",
    "failed": "Tool failed: {tool}",
    "not_found": "Tool not found: {tool}",
    "permission_denied": "Tool permission denied: {tool}"
  },
  "ui": {
    "loading": "Loading...",
    "error": "An error occurred",
    "success": "Operation completed successfully",
    "warning": "Warning",
    "info": "Information",
    "confirm": "Please confirm",
    "cancel": "Cancel",
    "ok": "OK",
    "yes": "Yes",
    "no": "No"
  },
  "validation": {
    "required": "This field is required",
    "invalid_format": "Invalid format",
    "too_short": "Value is too short",
    "too_long": "Value is too long",
    "invalid_range": "Value is out of valid range",
    "invalid_type": "Invalid data type",
    "unique_constraint": "Value must be unique",
    "file_not_found": "File not found",
    "directory_not_found": "Directory not found",
    "permission_denied": "Permission denied"
  },
  "service": {
    "initializing_live2d": "Initializing Live2D: {model}",
    "live2d_initialized": "✅ Live2D model initialized successfully: {info}",
    "live2d_error": "❌ Error initializing Live2D: {error}",
    "live2d_proceed_without": "Try to proceed without Live2D...",
    "initializing_asr": "Initializing ASR: {model}",
    "asr_already_initialized": "ASR already initialized with the same config.",
    "initializing_tts": "Initializing TTS: {model}",
    "tts_already_initialized": "TTS already initialized with the same config.",
    "vad_disabled": "VAD is disabled.",
    "initializing_vad": "Initializing VAD: {model}",
    "vad_already_initialized": "VAD already initialized with the same config.",
    "initializing_agent": "Initializing Agent: {agent}",
    "agent_already_initialized": "Agent already initialized with the same config.",
    "agent_init_failed": "Failed to initialize agent: {error}",
    "translation_disabled": "Translation is disabled.",
    "translation_already_initialized": "Translation already initialized with the same config.",
    "server_registry_initialized": "ServerRegistry initialized or referenced.",
    "tool_manager_initialized": "ToolManager initialized with dynamically fetched tools.",
    "mcp_client_initialized": "MCPClient initialized for this session.",
    "tool_executor_initialized": "ToolExecutor initialized for this session.",
    "stream_json_detector_initialized": "StreamJSONDetector initialized for this session.",
    "closing_resources": "Closing ServiceContext resources...",
    "service_context_closed": "ServiceContext closed.",
    "tool_adapter_initialized": "Initializing shared ToolAdapter within load_from_config.",
    "system_prompt_header": "\\n === System Prompt ===",
    "config_switched": "Configuration switched to {config}",
    "config_switch_error": "Error switching configuration: {error}",
    "dynamically_generated_mcp_prompt": "Dynamically generated MCP prompt string (length: {length}).",
    "dynamically_formatted_tools": "Dynamically formatted tools - OpenAI: {openai}, Claude: {claude}.",
    "failed_dynamic_mcp_tool_construction": "Failed during dynamic MCP tool construction: {error}",
    "mcp_enabled_but_server_registry_not_available": "MCP enabled but ServerRegistry not available. MCPClient not created.",
    "mcp_client_or_tool_manager_not_available": "MCPClient or ToolManager not available. ToolExecutor not created.",
    "use_mcpp_is_true_but_mcp_enabled_servers_list_is_empty": "use_mcpp is True, but mcp_enabled_servers list is empty. MCP components not initialized.",
    "mcp_components_not_initialized": "MCP components not initialized (use_mcpp is False or no enabled servers).",
    "closing_service_context_resources": "Closing ServiceContext resources...",
    "closing_mcp_client_for_context_instance": "Closing MCPClient for context instance {context_id}...",
    "loaded_service_context_with_cache": "Loaded service context with cache: {character_config}",
    "initializing_shared_server_registry_within_load_from_config": "Initializing shared ServerRegistry within load_from_config.",
    "initializing_shared_tool_adapter_within_load_from_config": "Initializing shared ToolAdapter within load_from_config.",
    "initializing_translator": "Initializing Translator: {provider}",
    "failed_to_load_configuration_from": "Failed to load configuration from {config_file_name}",
    "error_switching_configuration": "Error switching configuration: {error}"
  },
  "mcp": {
    "client_initialized": "MCPC: Initialized MCPClient instance.",
    "starting_connection": "MCPC: Starting and connecting to server '{server}'...",
    "connection_successful": "MCPC: Successfully connected to server '{server}'.",
    "connection_failed": "MCPC: Failed to connect to server '{server}': {error}",
    "client_closed": "MCPC: Client instance closed.",
    "closing_connections": "MCPC: Closing client instance and {count} active connections...",
    "session_close_error": "MCPC: Error closing session for server '{server}': {error}",
    "exit_stack_error": "MCPC: Error closing exit stack: {error}",
    "running_tool_construction": "MC: Running dynamic tool construction for servers: {servers}",
    "total_tools_fetched": "MC: Total tools fetched: {count}",
    "servers_info": "MC: Servers info: {servers}",
    "available_tools": "MC: Available tools: {tools}",
    "tools_formatted": "MC: Successfully formatted {openai} tools for OpenAI and {claude} tools for Claude.",
    "no_tools_found": "MC: No tools found from any enabled servers.",
    "tool_manager_initialized": "ToolManager initialized with {openai} OpenAI tools and {claude} Claude tools.",
    "openai_tools_available": "OpenAI tools available: {tools}",
    "claude_tools_available": "Claude tools available: {tools}",
    "no_servers_found": "MCPSM: No servers found in the config file.",
    "finished_constructing_prompt": "MC: Finished constructing MCP prompt string.",
    "invalid_tool_structure": "Skipping invalid tool structure in prompt mode JSON",
    "calling_tool": "MCPC: Calling tool '{tool}' on server '{server}'...",
    "tool_error": "MCPC: Error calling tool '{tool}': {error}",
    "tool_no_content": "MCPC: Tool '{tool}' returned no content. Returning empty content_items."
  }
} 