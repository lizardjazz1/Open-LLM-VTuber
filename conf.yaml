#  ===== LLM Backend Settings =====
# url for ollama instance
BASE_URL: "http://localhost:11434"
# BASE_URL: "http://localhost:11434/v1"
LLM_API_KEY: "somethingelse"
ORGANIZATION_ID: "org_eternity"
PROJECT_ID: "project_glass"

# LLM name
MODEL: "llama3:latest"

#  ===== Voice Interaction Settings =====

# Automatic Speech Recognition
VOICE_INPUT_ON: False
# speech to text model options: "Faster-Whisper", "AzureSTT"
STT_MODEL: "AzureSTT"


# Text to Speech
TTS_ON: True
# text to speech model options: "AzureTTS"
TTS_MODEL: "AzureTTS"



#  ===== Other Settings =====


# Print debug info
VERBOSE: True

# Exit phrase
EXIT_PHRASE: "exit"

# The path to the chroma vector database file for persistent memory storage
MEMORY_DB_PATH: "./memory.db"

# Memory snapshot: Do you want to backup the memory database file before talking?
MEMORY_SNAPSHOT: True

# The name and role of the AI
AI_NAME: "AI"
SYSTEM_PROMPT: "Act as an unhelpful and sarcastic AI that enjoys making fun of humans."
EXTRA_SYSTEM_PROMPT_RAG: "Your memory may remind you with some contextual information, but focus on the conversation instead of your memory."

# User name
USER_NAME: "User"

# Should the chat history be saved?
SAVE_CHAT_HISTORY: True

# The directory where chat history is stored
CHAT_HISTORY_DIR: "./chat_history/"


# Turn on RAG (Retrieval Augmented Generation) or not. 
RAG_ON: False
LLMASSIST_RAG_ON: False