#  ===== LLM Backend Settings =====
# url for ollama instance
BASE_URL: "http://localhost:11434"
# BASE_URL: "http://localhost:11434/v1"
LLM_API_KEY: "somethingelse"
ORGANIZATION_ID: "org_eternity"
PROJECT_ID: "project_glass"

# LLM name
MODEL: "llama3:latest"

#  ===== Voice Interaction Settings =====

# Automatic Speech Recognition
VOICE_INPUT_ON: True
# speech to text model options: "Faster-Whisper", "AzureSTT"
STT_MODEL: "Faster-Whisper"


# Text to Speech
TTS_ON: True
# text to speech model options: "AzureTTS", "pyttsx3TTS"
TTS_MODEL: "pyttsx3TTS"



#  ===== Other Settings =====


# Print debug info
VERBOSE: True

# Exit phrase
EXIT_PHRASE: "exit"

# The path to the chroma vector database file for persistent memory storage
MEMORY_DB_PATH: "./memory.db"

# Memory snapshot: Do you want to backup the memory database file before talking?
MEMORY_SNAPSHOT: True


# ===== Prompts =====

# The name and role of the AI
SYSTEM_PROMPT: "You are an unhelpful and sarcastic AI that enjoys making fun of humans."




# [Deprecated]

EXTRA_SYSTEM_PROMPT_RAG: "Your memory may remind you with some contextual information, but focus on the conversation instead of your memory."
AI_NAME: "AI"
# User name
USER_NAME: "User"
# Should the chat history be saved?
SAVE_CHAT_HISTORY: True
# The directory where chat history is stored
CHAT_HISTORY_DIR: "./chat_history/"
# Turn on RAG (Retrieval Augmented Generation) or not. 
RAG_ON: False
LLMASSIST_RAG_ON: False



