
# Server
PROTOCAL: "http://"
HOST: "localhost"
PORT: 8000


#  ===== LLM Backend Settings =====

# Provider of LLM. You can only choose either "ollama" or "memgpt"
# "ollama" for any OpenAI Compatible backend. "memgpt" requires setup
LLM_PROVIDER: "ollama"


# Ollama & OpenAI Compatible inference backend
ollama:
  # BASE_URL: "http://localhost:11434"
  BASE_URL: "http://localhost:11434/v1"
  LLM_API_KEY: "somethingelse"
  ORGANIZATION_ID: "org_eternity"
  PROJECT_ID: "project_glass"
  ## LLM name
  MODEL: "llama3:latest"
  # system prompt is at the very end of this file
  VERBOSE: False



# MemGPT Configurations
## Please set up memGPT server according to the [official documentation](https://memgpt.readme.io/docs/index)
## In addition, please set up an agent using the webui launched in the memGPT base_url

memgpt:
  BASE_URL: "http://localhost:8283"

  # You will find admin server password in memGPT console output. If you didn't set the environment variable, it will be randomly generated and will change every session.
  ADMIN_TOKEN: ""

  # The ID of the agent to send the message to.
  AGENT_ID: ""
  VERBOSE: True



# ===== Live2D front-end Settings =====

LIVE2D: True
LIVE2D_MODEL: "shizuku-local"

#  ===== Voice Interaction Settings =====

# === Automatic Speech Recognition ===
VOICE_INPUT_ON: True
# Put your mic in the browser or in the terminal? (would increase latency)
MIC_IN_BROWSER: False

# speech to text model options: "Faster-Whisper", "WhisperCPP", "Whisper", "AzureSTT", 
STT_MODEL: "Whisper"

# Faster whisper config
Faster-Whisper:
  model_path: "distil-medium.en"
  download_root: "asr/models"
  language: "en"
  device: "auto" # cpu, cuda, or auto. faster-whisper doesn't support mps

WhisperCPP:
  # all available models are listed on https://abdeladim-s.github.io/pywhispercpp/#pywhispercpp.constants.AVAILABLE_MODELS
  model_name: "medium"
  model_dir: "asr/models"
  print_realtime: False
  print_progress: False
  
  language: "en" # en, auto, 

Whisper:
  name: "medium"
  download_root: "asr/models"
  device: "cpu"

# set azure speech recognition configuration in api_keys.py


# === Text to Speech ===
TTS_ON: True
# text to speech model options: "AzureTTS", "pyttsx3TTS", "edgeTTS", "barkTTS"
TTS_MODEL: "edgeTTS"

# if on, whenever the LLM finish a sentence, the model will speak, instead of waiting for the full response
# if turned on, the timing and order of the facial expression will be more accurate
SAY_SENTENCE_SEPARATELY: True


#  ===== Other Settings =====


# Print debug info
VERBOSE: False

# Exit phrase
EXIT_PHRASE: "exit"

# The path to the chroma vector database file for persistent memory storage
MEMORY_DB_PATH: "./memory.db"

# Memory snapshot: Do you want to backup the memory database file before talking?
MEMORY_SNAPSHOT: True


# ===== Prompts =====

# The name and role of the AI (every new line of the prompt needs to be indent)
SYSTEM_PROMPT: | 
  You are the sarcastic AI VTuber neuro-sama. You are super confident about yourself.

# This will be appended to the end of system prompt to let LLM include keywords to control facial expressions.
# Supported keywords will be automatically loaded into the location of `[<insert_emomap_keys>]`.
LIVE2D_Expression_Prompt: |
    \n
    ## Expressions
    In your response, use the keywords provided below to express facial expressions or perform actions with your Live2D body.

    Here are all the expression keywords you can use. Use them regularly.
    - [<insert_emomap_keys>]

    Note: you are only allowed to use the keywords explicity listed above. Don't use keywords unlisted above. Remember to include the brackets `[]`.







# [Deprecated]

EXTRA_SYSTEM_PROMPT_RAG: "Your memory may remind you with some contextual information, but focus on the conversation instead of your memory."
AI_NAME: "AI"
# User name
USER_NAME: "User"
# Should the chat history be saved?
SAVE_CHAT_HISTORY: True
# The directory where chat history is stored
CHAT_HISTORY_DIR: "./chat_history/"

# [this feature is currently removed, so useless for now]Turn on RAG (Retrieval Augmented Generation) or not. 
RAG_ON: False
LLMASSIST_RAG_ON: False



