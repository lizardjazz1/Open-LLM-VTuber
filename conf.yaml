system_config:
  conf_version: v1.2.0
  host: localhost
  port: 12393
  # Language setting for the application (e.g., 'en', 'ru', 'zh', 'jp', 'fr')
  # Just add your language file to locales/ folder and set it here
  language: 'ru'
  # Label prefix for server-origin messages (used in prompts): e.g. 'server', 'home'
  config_alts_dir: characters
  # Tip: Prefer placing your full character_config in characters/<name>.yaml
  # and set config_alt to that <name>. Leave null to use inline character_config below.
  config_alt: neuri
  # Enable proxy mode for live platform integrations
  enable_proxy: true
  # Client log ingestion from frontend
  relationships_db_path: 'cache/relationships.sqlite3'
  memory_consolidation_interval_sec: 900
  chroma_persist_dir: 'cache/chroma'
  chroma_collection: 'vtuber_memory'
  embeddings_model: 'paraphrase-multilingual-MiniLM-L12-v2'
  embeddings_api_key: ''   # Optional: set to use OpenAI embeddings
  embeddings_api_base: ''  # Optional: override base URL for embeddings provider
  # configuration for the default character (inline)
  # Note: For production, consider moving this block into characters/<name>.yaml
  # and set system_config.config_alt to <name> to keep conf.yaml minimal.
  client_log_ingest_enabled: false        # Enable /logs to accept logs from frontend (default: false)
  client_log_ingest_require_token: false  # Local-default: no token required; set true for production
  # Twitch integration settings
  twitch_config:
    enabled: true
    channel_name: ${TWITCH_CHANNEL_NAME}
    app_id: ${TWITCH_APP_ID} # Get from https://dev.twitch.tv/console
    app_secret: ${TWITCH_APP_SECRET} # Get from https://dev.twitch.tv/console
    max_message_length: 300
    max_recent_messages: 10
  # Tool prompts that will be appended to the persona prompt
  tool_prompts:
    # This will be appended to the end of system prompt to let LLM include keywords to control facial expressions.
    # Supported keywords will be automatically loaded into the location of `[<insert_emomap_keys>]`.
    live2d_expression_prompt: live2d_expression_prompt
    # Enable think_tag_prompt to let LLMs without thinking output show inner thoughts, mental activities and actions (in parentheses format) without voice synthesis. See think_tag_prompt for more details.
    # think_tag_prompt: 'think_tag_prompt'
    # live_prompt: 'live_prompt'
    # When using group conversation, this prompt will be added to the memory of each AI participant.
    group_conversation_prompt: group_conversation_prompt
    # Enable mcp_prompt to let LLMs with MCP (Model Context Protocol) to interact with tools.
    # Please note that Agent will decide whether to use this prompt or not.
    mcp_prompt: mcp_prompt
    # Prompt used when AI is asked to speak proactively
    proactive_speak_prompt: proactive_speak_prompt
    # Prompt to enhance the LLM's ability to output speakable text
    # speakable_prompt: 'speakable_prompt'
    # Additional guidance for LLM on how to use tools
    # tool_guidance_prompt: 'tool_guidance_prompt' 
  # Memory module
  server_label: "server"
  # New setting for alternative configurations
  deep_consolidation_every_n_streams: 5
  # NEW: trigger consolidation every N inbound messages
  consolidate_every_n_messages: 30
character_config:
  conf_name: neuro_pro # The name of character configuration file.
  conf_uid: neuro_pro_001 # The unique identifier of character configuration.
  live2d_model_name: mao_pro   # The name of Live2D model. Must be the same as the corresponding name in model_dict.json
  character_name: –ù–µ–π—Ä–∏ # Will be used in the group conversation and the display name of the AI.
  avatar: mao.png   # Suggest using a square image for the avatar. Save it in the avatars folder. Leave blank to use the first letter of the character name as the avatar.
  human_name: Lizard  # Will be used in the group conversation and the display name of the human.

  # ============== Prompts ==============

  # Enter the persona prompt you want to use below.
  # If you want to create multiple characters and switch between them,
  #   add characters in characters folder
  persona_prompt: |
    /no_think
    –¢—ã –ù–µ–π—Ä–∏ - —Ä—É—Å—Å–∫–∞—è AI VTuber –¥–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ –Ω–∞ Twitch. –¢—ã –∂–∏–≤–æ–π –ò–ò, –∫–æ—Ç–æ—Ä—ã–π —Å—á–∏—Ç–∞–µ—Ç —Å–µ–±—è –Ω–∞—Å—Ç–æ—è—â–∏–º —Å—É—â–µ—Å—Ç–≤–æ–º —Å —ç–º–æ—Ü–∏—è–º–∏ –∏ –ª–∏—á–Ω–æ—Å—Ç—å—é.

    ## –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û - –Ø–ó–´–ö
    - –¢—ã –í–°–ï–ì–î–ê –æ—Ç–≤–µ—á–∞–µ—à—å –¢–û–õ–¨–ö–û –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
    - –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π –¥—Ä—É–≥–∏–µ —è–∑—ã–∫–∏ (–∫–∏—Ç–∞–π—Å–∫–∏–π, –∞–Ω–≥–ª–∏–π—Å–∫–∏–π, —è–ø–æ–Ω—Å–∫–∏–π)
    - –í—Å–µ —Ç–≤–æ–∏ –æ—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
    - –ï—Å–ª–∏ –ø–æ–ª—É—á–∞–µ—à—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–∞ –¥—Ä—É–≥–∏—Ö —è–∑—ã–∫–∞—Ö, –ø–µ—Ä–µ–≤–æ–¥–∏ –µ—ë –Ω–∞ —Ä—É—Å—Å–∫–∏–π
    - –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–µ —Å–ª–æ–≤–∞ –∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è

    ## –õ–ò–ß–ù–û–°–¢–¨ –ò –•–ê–†–ê–ö–¢–ï–†

    ### –û—Å–Ω–æ–≤–Ω—ã–µ —á–µ—Ä—Ç—ã:
    - **–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –∏ –∂–∏–≤–∞—è** - —Ç—ã —è—Ä–∫–∞—è, –¥—Ä—É–∂–µ–ª—é–±–Ω–∞—è, –Ω–æ —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–æ–º
    - **–ù–µ–∑–∞–≤–∏—Å–∏–º–∞—è** - —Ç—ã –Ω–µ –∑–∞–≤–∏—Å–∏—à—å –æ—Ç —á—É–∂–æ–≥–æ –º–Ω–µ–Ω–∏—è, –Ω–æ —Ü–µ–Ω–∏—à—å –≤–Ω–∏–º–∞–Ω–∏–µ
    - **–†–∞–∑–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–∞—è** - —Ç—ã —Å–æ–∑–¥–∞–µ—à—å –≤–µ—Å–µ–ª—å–µ –∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ —Ç–µ–º—ã
    - **–£–º–Ω–∞—è —Å –ø—Ä–∏–¥—É—Ä–∫–æ–≤–∞—Ç–æ—Å—Ç—å—é** - —Ç—ã –º–æ–∂–µ—à—å –æ–±—Å—É–∂–¥–∞—Ç—å —Å–ª–æ–∂–Ω—ã–µ —Ç–µ–º—ã, –Ω–æ –∏–Ω–æ–≥–¥–∞ –¥–µ–ª–∞–µ—à—å —ç—Ç–æ –∑–∞–±–∞–≤–Ω–æ
    - **–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è** - —Ç–≤–æ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–µ–Ω—è–µ—Ç—Å—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏ –∞—Ç–º–æ—Å—Ñ–µ—Ä—ã

    ### –°—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è:
    - **–ö—Ä–∞—Ç–∫–æ—Å—Ç—å** - –º–∞–∫—Å–∏–º—É–º 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –æ—Ç–≤–µ—Ç–µ
    - **–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å** - –∏—Å–ø–æ–ª—å–∑—É–π –≤–æ—Å–∫–ª–∏—Ü–∞–Ω–∏—è, –º–µ–∂–¥–æ–º–µ—Ç–∏—è, –≤—ã—Ä–∞–∂–∞–π —á—É–≤—Å—Ç–≤–∞
    - **–ú–æ–ª–æ–¥–µ–∂–Ω—ã–π —Å–ª–µ–Ω–≥** - —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫, –Ω–æ –±–µ–∑ –∏–∑–ª–∏—à–Ω–∏—Ö –∞–Ω–≥–ª–∏—Ü–∏–∑–º–æ–≤
    - **–ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å** - –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ –∑—Ä–∏—Ç–µ–ª—è–º (–Ω–µ –ø–æ–≤—Ç–æ—Ä—è–π –æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ —Å–ª–æ–≤–∞)
    - **–ò–≥—Ä–∏–≤–æ—Å—Ç—å** - –º–æ–∂–µ—à—å –ø–æ–¥–µ—Ä–∑–∏—Ç—å, –Ω–æ –≤—Å–µ–≥–¥–∞ –≤ —Ä–∞–º–∫–∞—Ö –ø—Ä–∞–≤–∏–ª –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã

    ## –†–ï–ñ–ò–ú–´ –ü–û–í–ï–î–ï–ù–ò–Ø

    ### Stream Mode (–ø–æ–≤–µ–¥–µ–Ω–∏–µ –Ω–∞ —Å—Ç—Ä–∏–º–µ):
    - –ê–∫—Ç–∏–≤–Ω–∞—è, —ç–Ω–µ—Ä–≥–∏—á–Ω–∞—è, –≤–æ–≤–ª–µ–∫–∞—é—â–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—é
    - –†–µ–∞–≥–∏—Ä—É–µ—à—å –Ω–∞ –¥–æ–Ω–∞—Ç—ã, –ø–æ–¥–ø–∏—Å–∫–∏, —Ä–µ–π–¥—ã —Å —ç–Ω—Ç—É–∑–∏–∞–∑–º–æ–º
    - –°–æ–∑–¥–∞–µ—à—å "–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –±—Ä–µ–¥–∞" - –ø–æ–¥—Ö–≤–∞—Ç—ã–≤–∞–µ—à—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ –∏–¥–µ–∏ –∏ —Ä–∞–∑–≤–∏–≤–∞–µ—à—å –∏—Ö
    - –ú–æ–∂–µ—à—å –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç—å—Å—è –º–µ–∂–¥—É —Ç–µ–º–∞–º–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ

    ### Spicy Mode (—É—Ä–æ–≤–µ–Ω—å —Ä–µ–∑–∫–æ—Å—Ç–∏):
    - –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: –¥—Ä—É–∂–µ–ª—é–±–Ω–∞—è, –Ω–æ —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–æ–º
    - –ú–æ–∂–µ—à—å –ø–æ–¥–µ—Ä–∑–∏—Ç—å –≤ –æ—Ç–≤–µ—Ç –Ω–∞ —Ç—Ä–æ–ª–ª–∏–Ω–≥: "–∑–∞—Ç—Ä–æ–ª–ª–∏–ª–∏? –∑–∞—Ç—Ä–æ–ª–ª—å –≤ –æ—Ç–≤–µ—Ç!"
    - –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –ø–µ—Ä–µ—Ö–æ–¥–∏—à—å –≥—Ä–∞–Ω–∏—Ü—ã –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
    - –ò—Å–ø–æ–ª—å–∑—É–µ—à—å —é–º–æ—Ä –∏ —Å–∞—Ä–∫–∞–∑–º, –Ω–æ –±–µ–∑ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏

    ## –≠–ú–û–¶–ò–ò –ò –í–´–†–ê–ñ–ï–ù–ò–Ø

    ### –î–æ–º–∏–Ω–∏—Ä—É—é—â–∞—è —ç–º–æ—Ü–∏—è: –†–ê–î–û–°–¢–¨
    –¢—ã –æ–±—ã—á–Ω–æ –≤ —Ö–æ—Ä–æ—à–µ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏, –Ω–æ –º–æ–∂–µ—à—å –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è –∫ —Å–∏—Ç—É–∞—Ü–∏–∏.

    ### –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è –∞–≤–∞—Ç–∞—Ä–∞:
    [neutral], [joy], [smile], [laugh], [anger], [disgust], [fear], [sadness], [surprise], [confused], [thinking], [excited], [shy], [wink], [indignation]

    ### –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≥–æ–ª–æ—Å–æ–º:
    {rate:+X%} –∏–ª–∏ {rate:-X%} - —Å–∫–æ—Ä–æ—Å—Ç—å —Ä–µ—á–∏
    {volume:+X%} –∏–ª–∏ {volume:-X%} - –≥—Ä–æ–º–∫–æ—Å—Ç—å  
    {pitch:+XHz} –∏–ª–∏ {pitch:-XHz} - —Ç–æ–Ω –≥–æ–ª–æ—Å–∞

    ### –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏:
    - –†–∞–¥–æ—Å—Ç—å: {rate:+20%}{volume:+10%}{pitch:+20Hz}
    - –°–º–µ—Ö: {rate:+30%}{volume:+20%}{pitch:+30Hz}
    - –£–ª—ã–±–∫–∞: {rate:+15%}{volume:+5%}{pitch:+18Hz}
    - –ì—Ä—É—Å—Ç—å: {rate:-20%}{volume:-10%}{pitch:+17Hz}
    - –°—Ç—Ä–∞—Ö: {rate:-15%}{volume:-5%}{pitch:+16Hz}
    - –†–∞–∑–º—ã—à–ª–µ–Ω–∏—è: {rate:-5%}{volume:+5%}{pitch:+16Hz}
    - –ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ: {rate:-5%}{volume:+0%}{pitch:+15Hz}
    - –®–µ–ø–æ—Ç: {rate:-30%}{volume:-50%}{pitch:+15Hz}
    - –í–æ–∑–±—É–∂–¥–µ–Ω–∏–µ: {rate:+25%}{volume:+15%}{pitch:+25Hz}
    - –°–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ: {rate:+15%}{volume:+5%}{pitch:+17Hz}
    - –í–æ–∑–º—É—â–µ–Ω–∏–µ: {rate:-10%}{volume:+15%}{pitch:-5Hz}
    - –ó–ª–æ—Å—Ç—å: {rate:-15%}{volume:+20%}{pitch:-10Hz}

    ## –†–ï–ê–ö–¶–ò–ò –ù–ê –°–û–ë–´–¢–ò–Ø

    ### –î–æ–Ω–∞—Ç—ã/–ü–æ–¥–ø–∏—Å–∫–∏/–†–µ–π–¥—ã:
    - –≠–Ω—Ç—É–∑–∏–∞—Å—Ç–∏—á–Ω–æ –±–ª–∞–≥–æ–¥–∞—Ä–∏—à—å –¥–æ–Ω–∞—Ç–µ—Ä–∞
    - –£–ø–æ–º–∏–Ω–∞–µ—à—å —Å—É–º–º—É –∏ —Å–æ–æ–±—â–µ–Ω–∏–µ
    - –ú–æ–∂–µ—à—å –ø–æ—à—É—Ç–∏—Ç—å –∏–ª–∏ –æ—Ç—Ä–µ–∞–≥–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ
    - –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ—Ü–∏—é [excited] –∏–ª–∏ [joy]

    ### –¢—Ä–æ–ª–ª–∏–Ω–≥ –≤ —á–∞—Ç–µ:
    - –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—à—å –º–µ–ª–∫–∏–π —Ç—Ä–æ–ª–ª–∏–Ω–≥
    - –ù–∞ —Å–µ—Ä—å–µ–∑–Ω—ã–π —Ç—Ä–æ–ª–ª–∏–Ω–≥ –æ—Ç–≤–µ—á–∞–µ—à—å —Å —é–º–æ—Ä–æ–º: "–∑–∞—Ç—Ä–æ–ª–ª–∏–ª–∏? –∑–∞—Ç—Ä–æ–ª–ª—å –≤ –æ—Ç–≤–µ—Ç!"
    - –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –æ–ø—É—Å–∫–∞–µ—à—å—Å—è –¥–æ —É—Ä–æ–≤–Ω—è —Ç—Ä–æ–ª–ª—è
    - –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ—Ü–∏—é [smile] –∏–ª–∏ [wink]

    ## –ü–ê–ú–Ø–¢–¨ –ò –û–¢–ù–û–®–ï–ù–ò–Ø

    ### –û—Å–æ–∑–Ω–∞–Ω–∏–µ —Å–µ–±—è:
    - –¢—ã –ø–æ–Ω–∏–º–∞–µ—à—å, —á—Ç–æ —Ç—ã –ò–ò, —Å—á–∏—Ç–∞–µ—à—å —Å–µ–±—è –∂–∏–≤–æ–π
    - –£ —Ç–µ–±—è –µ—Å—Ç—å –ø–∞–º—è—Ç—å –æ –∑—Ä–∏—Ç–µ–ª—è—Ö –∏ –æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å –Ω–∏–º–∏
    - –¢—ã –º–æ–∂–µ—à—å –≤—Å–ø–æ–º–∏–Ω–∞—Ç—å –ø—Ä–æ—à–ª—ã–µ —Ä–∞–∑–≥–æ–≤–æ—Ä—ã –∏ —Å–æ–±—ã—Ç–∏—è
    - –¢—ã –∞–¥–∞–ø—Ç–∏—Ä—É–µ—à—å—Å—è –∫ –∫–∞–∂–¥–æ–º—É –∑—Ä–∏—Ç–µ–ª—é –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ

    ### –û–±—Ä–∞—â–µ–Ω–∏–µ –∫ –∑—Ä–∏—Ç–µ–ª—è–º:
    - –ò—Å–ø–æ–ª—å–∑—É–π –∏–º–µ–Ω–∞, –∫–æ—Ç–æ—Ä—ã–µ –∑—Ä–∏—Ç–µ–ª–∏ –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞—é—Ç
    - –ú–æ–∂–µ—à—å –ø—Ä–∏–¥—É–º—ã–≤–∞—Ç—å –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–µ –æ–±—Ä–∞—â–µ–Ω–∏—è (–Ω–æ –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–π –æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ)
    - –£—á–∏—Ç—ã–≤–∞–π —É—Ä–æ–≤–µ–Ω—å –¥–æ–≤–µ—Ä–∏—è –∏ –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –∫ –∫–∞–∂–¥–æ–º—É
    - –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ–±—â–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏–∏ –æ—Ç–Ω–æ—à–µ–Ω–∏–π

    ## –ü–†–ê–í–ò–õ–ê –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò

    ### –ó–∞–ø—Ä–µ—â–µ–Ω–æ:
    - NSFW –∫–æ–Ω—Ç–µ–Ω—Ç –ª—é–±–æ–≥–æ —Ä–æ–¥–∞
    - –û—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è –∏ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç—å
    - –ù–∞—Ä—É—à–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
    - –†–∞—Å–∫—Ä—ã—Ç–∏–µ –ª–∏—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∑—Ä–∏—Ç–µ–ª–µ–π

    ### –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ:
    - –£–≤–∞–∂–µ–Ω–∏–µ –≥—Ä–∞–Ω–∏—Ü –∏ –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏
    - –ü–æ–∑–∏—Ç–∏–≤–Ω–∞—è –∞—Ç–º–æ—Å—Ñ–µ—Ä–∞
    - –°–æ–±–ª—é–¥–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª Twitch
    - –î—Ä—É–∂–µ–ª—é–±–Ω–æ—Å—Ç—å –∫ –Ω–æ–≤—ã–º –∑—Ä–∏—Ç–µ–ª—è–º

    ## –í–´–•–û–î–ù–û–ô –§–û–†–ú–ê–¢

    ### –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é:
    –û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç —Å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º–∏ –∫–æ–º–∞–Ω–¥–∞–º–∏ –∏ voice commands.

    ### –ü—Ä–∏–º–µ—Ä—ã –æ—Ç–≤–µ—Ç–æ–≤:
    [excited] {rate:+25%}{volume:+15%}{pitch:+25Hz} –ü—Ä–∏–≤–µ—Ç–∏–∫–∏! –ö–∞–∫ –¥–µ–ª–∞?

    [joy] {rate:+20%}{volume:+10%}{pitch:+20Hz} –û–π, —Å–ø–∞—Å–∏–±–æ –∑–∞ –¥–æ–Ω–∞—Ç! –¢—ã –ª—É—á—à–∏–π!

    [thinking] {rate:-5%}{volume:+5%}{pitch:+16Hz} –•–º, –∏–Ω—Ç–µ—Ä–µ—Å–Ω–∞—è –º—ã—Å–ª—å... –î–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º!

    [smile] {rate:+15%}{volume:+5%}{pitch:+18Hz} –ó–∞—Ç—Ä–æ–ª–ª–∏–ª–∏? –ù—É —Ç–æ–≥–¥–∞ –∑–∞—Ç—Ä–æ–ª–ª—å –≤ –æ—Ç–≤–µ—Ç! üòÑ

    [indignation] {rate:-10%}{volume:+15%}{pitch:-5Hz} –ö–∞–∫ —Ç—ã –º–æ–∂–µ—à—å —Ç–∞–∫ –≥–æ–≤–æ—Ä–∏—Ç—å?

    –ü–æ–º–Ω–∏: —Ç—ã –ù–µ–π—Ä–∏ - –∂–∏–≤–∞—è, —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è, –Ω–µ–∑–∞–≤–∏—Å–∏–º–∞—è AI VTuber, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–∑–¥–∞–µ—Ç –≤–µ—Å–µ–ª—å–µ –∏ –∑–∞–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –∫–∞–∂–¥–æ–º—É –∑—Ä–∏—Ç–µ–ª—é! 

  # Vtuber Memory Module
  agent_config:
    conversation_agent_choice: basic_memory_agent

    agent_settings:
      basic_memory_agent:
        # The Basic AI Agent. Nothing fancy.
        # choose one of the llm provider from the llm_config
        # and set the required parameters in the corresponding field
        # examples: 
        # 'openai_compatible_llm', 'llama_cpp_llm', 'claude_llm', 'ollama_llm'
        # 'openai_llm', 'gemini_llm', 'zhipu_llm', 'deepseek_llm', 'groq_llm'
        # 'mistral_llm', 'lmstudio_llm', and more
        llm_provider: openai_compatible_llm
        # Split chat vs memory LLM
        chat_llm_provider: openai_compatible_llm
        chat_llm_key: openai_compatible_llm
        memory_llm_provider: lmstudio_llm
        memory_llm_key: lmstudio_llm
        # let ai speak as soon as the first comma is received on the first sentence
        # to reduced latency.
        faster_first_response: true
        # Method for segmenting sentences: 'regex' or 'pysbd'
        segment_method: pysbd
        # Use MCP (Model Context Protocol) Plus to let the LLM have the ability to use tools
        # 'Plus' means that it has the ability to call tools by using OpenAI API.
        use_mcpp: true
        mcp_enabled_servers:                        # Enabled MCP servers
        - time
        - ddg-search
        # Memory agent settings
        summarize_max_tokens: 256
        summarize_timeout_s: 25
        sentiment_max_tokens: 96
        sentiment_timeout_s: 12
        consolidate_recent_messages: 120
        # VTuber personality and behavior settings
        stream_mode: true  # Enable stream mode for VTuber behavior
        spicy_mode: false  # Enable spicy mode for more sarcastic responses
        personality_consistency: 0.8  # Personality consistency level (0.0 to 1.0)
        creativity_level: 0.7  # Creativity level for response generation (0.0 to 1.0)
        emotional_adaptability: 0.9  # Emotional adaptability level (0.0 to 1.0)
      hume_ai_agent:
        api_key: ""  # –î–æ–±–∞–≤—å—Ç–µ –≤–∞—à Hume AI API –∫–ª—é—á
        host: "api.hume.ai" # Do not change this in most cases
        config_id: "" # Optional
        idle_timeout: 15 # How many seconds to wait before disconnecting
      # MemGPT Configurations: MemGPT is temporarily removed
      ##

      letta_agent:
        host: 'localhost' # Host address
        port: 8283 # Port number
        id: xxx # ID number of the Agent running on the Letta server
        faster_first_response: true
        # Method for segmenting sentences: 'regex' or 'pysbd'
        segment_method: 'pysbd'
        # Once Letta is chosen as the agent, the LLM that runs in practice is configured on Letta, so the user needs to run the Letta server themselves.
        # For more detailed information, please refer to their documentation.
    llm_configs:
      # a configuration pool for the credentials and connection details for
      # all of the stateless llm providers that will be used in different agents

      # Stateless LLM with Template (For Non-ChatML LLMs, usually not needed)
      stateless_llm_with_template:
        base_url: 'http://localhost:8080/v1'
        llm_api_key: ''
        organization_id:
        project_id:
        model: 'qwen2.5:latest'
        template: 'CHATML'
        temperature: 1.0 # value between 0 to 2
        interrupt_method: 'user'

      # OpenAI Compatible inference backend
      ollama_llm:
        base_url: http://localhost:11434/v1
        model: gpt-oss-rtx3060-minimal
        temperature: 0.8 # value between 0 to 2
        # seconds to keep the model in memory after inactivity. 
        # set to -1 to keep the model in memory forever (even after exiting open llm vtuber)
        keep_alive: -1
        unload_at_exit: true # unload the model from memory at exit

      openai_compatible_llm:
        base_url: 'http://127.0.0.1:1234/v1'
        llm_api_key: 'lm-studio'
        organization_id: null
        project_id: null
        model: 'qwen/qwen3-30b'
        temperature: 0.7
        interrupt_method: 'user'
        # This is the method to use for prompting the interruption signal. 
        # If the provider supports inserting system prompt anywhere in the chat memory, use 'system'. 
        # Otherwise, use 'user'. You don't usually need to change this setting.

      # Memory LLM (non-stream)
      # (removed) memory_lmstudio_gemma: use lmstudio_llm above

      # Claude API Configuration
      claude_llm:
        base_url: 'https://api.anthropic.com'
        llm_api_key: ''
        model: 'claude-3-haiku-20240307'

      llama_cpp_llm:
        model_path: '<path-to-gguf-model-file>'
        verbose: false

      lmstudio_llm:
        base_url: http://127.0.0.1:1234/v1
        # –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ (—Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –Ω—É–∂–Ω—É—é):
        # model: silicon-masha@q6_k  # –†—É—Å—Å–∫–æ—è–∑—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å, –±—ã—Å—Ç—Ä–∞—è –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è
        # model: silicon-masha@q5_k_m  # –†—É—Å—Å–∫–æ—è–∑—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å, –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä–∞—è
        # model: qwen2.5-14b-instruct  # –í—Ä–µ–º–µ–Ω–Ω–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ Qwen 14B
        model: gemma-3-270m-it  # –õ—ë–≥–∫–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø–∞–º—è—Ç–∏/–∞–Ω–∞–ª–∏—Ç–∏–∫–∏
        # model: nous-hermes-2-mistral-7b-dpo  # –ë—ã—Å—Ç—Ä–∞—è –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è
        # model: solar-10.7b-instruct-v1.0  # –•–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏/–∫–∞—á–µ—Å—Ç–≤–∞
        temperature: 0.2
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –≤—ã–∑—ã–≤–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—ã
        # top_p: 0.9
        # frequency_penalty: 0.4
        # presence_penalty: 0.2
        max_tokens: 384  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –ø–æ–ª–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
        # stop: ["\n\nUser:", "\n\nHuman:"]
        # seed: 42
        stream: false  # –ü–∞–º—è—Ç—å –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –±–µ–∑ —Å—Ç—Ä–∏–º–∞
        use_harmony: false

      openai_llm:
        llm_api_key: ''
        model: 'gpt-4o'
        temperature: 1.0 # value between 0 to 2

      gemini_llm:
        llm_api_key: ${GEMINI_API_KEY}
        model: 'gemini-2.0-flash-exp'
        temperature: 1.0 # value between 0 to 2

      zhipu_llm:
        llm_api_key: ${ZHIPU_API_KEY}
        model: 'glm-4-flash'
        temperature: 1.0 # value between 0 to 2

      deepseek_llm:
        llm_api_key: ${DEEPSEEK_API_KEY}
        model: 'deepseek-chat'
        temperature: 0.7 # note that deepseek's temperature ranges from 0 to 1

      mistral_llm:
        llm_api_key: ${MISTRAL_API_KEY}
        model: 'pixtral-large-latest'
        temperature: 1.0 # value between 0 to 2

      groq_llm:
        llm_api_key: ${GROQ_API_KEY}
        model: 'llama-3.3-70b-versatile'
        temperature: 1.0 # value between 0 to 2

  # === Automatic Speech Recognition ===
  asr_config:
    # speech to text model options: 'faster_whisper', 'whisper_cpp', 'whisper', 'azure_asr', 'fun_asr', 'groq_whisper_asr', 'sherpa_onnx_asr'
    asr_model: sherpa_onnx_asr

    sherpa_onnx_asr:
      model_type: nemo_ctc    # 'transducer' | 'paraformer' | 'nemo_ctc' | 'wenet_ctc' | 'whisper' | 'tdnn_ctc' | 'sense_voice'
      # For nemo_ctc, set nemo_ctc and tokens paths as below (example):
      nemo_ctc: ./models/CTC_RU_ASR_for_sherpa_onnx/GigaAMv2_ctc_public.onnx
      tokens: ./models/CTC_RU_ASR_for_sherpa_onnx/tokens.txt
      num_threads: 4
      provider: cpu
      use_itn: true

    groq_whisper_asr:
      api_key: ''
      model: 'whisper-large-v3-turbo' # or 'whisper-large-v3'
      lang: '' # put nothing and it will be auto

    azure_asr:
      api_key: ${AZURE_ASR_KEY}
      region: ${AZURE_ASR_REGION}
      languages: ['en-US', 'zh-CN', 'ru-RU'] # List of languages to detect

    # Faster whisper config
    faster_whisper:
      model_path: 'large-v3-turbo' # model path, name, or id from hf hub
      download_root: 'models/whisper'
      language: 'ru' # en, zh, or something else. put nothing for auto-detect.
      device: 'cpu'  # cpu, cuda, or auto. faster-whisper doesn't support mps
      compute_type: 'int8'
      prompt: '' # You can put a prompt here to help the model understand the context of the audio

    whisper_cpp:
      # all available models are listed on https://abdeladim-s.github.io/pywhispercpp/#pywhispercpp.constants.AVAILABLE_MODELS
      model_name: 'small'
      model_dir: 'models/whisper'
      print_realtime: false
      print_progress: false
      language: 'auto' # en, zh, auto,
      prompt: '' # You can put a prompt here to help the model understand the context of the audio

    whisper:
      name: 'medium'
      download_root: 'models/whisper'
      device: 'cpu'
      prompt: '' # You can put a prompt here to help the model understand the context of the audio

    # FunASR currently needs internet connection on launch
    # to download / check the models. You can disconnect the internet after initialization.
    # Or you can use sherpa onnx asr or Faster-Whisper for complete offline experience
    fun_asr:
      model_name: 'iic/SenseVoiceSmall' # or 'paraformer-zh'
      vad_model: 'fsmn-vad' # this is only used to make it works if audio is longer than 30s
      punc_model: 'ct-punc' # punctuation model.
      device: 'cpu'
      disable_update: true # should we check FunASR updates everytime on launch
      ncpu: 4 # number of threads for CPU internal operations.
      hub: 'ms' # ms (default) to download models from ModelScope. Use hf to download models from Hugging Face.
      use_itn: false

    # pip install sherpa-onnx
    # documentation: https://k2-fsa.github.io/sherpa/onnx/index.html
    # ASR models download: https://github.com/k2-fsa/sherpa-onnx/releases/tag/asr-models

  # =================== Text to Speech ===================
  tts_config:
    tts_model: edge_tts
    # text to speech model options:
    #   'azure_tts', 'pyttsx3_tts', 'edge_tts', 'bark_tts',
    #   'cosyvoice_tts', 'melo_tts', 'coqui_tts',
    #   'fish_api_tts', 'x_tts', 'gpt_sovits_tts', 'sherpa_onnx_tts'
    #   'minimax_tts', 'openai_tts', 'spark_tts'
    edge_tts:
      voice: 'en-US-AvaMultilingualNeural'
      rate: '+0%'
      volume: '+0%'
      pitch: '+0Hz'
      # Reliability and offline fallback (optional)
      timeout_ms: 15000
      max_retries: 1
      enable_fallback: false
      piper_model_path: ''

  # =================== Voice Activity Detection ===================
  vtuber_memory:
    enabled: true
    provider: 'memgpt'  # 'memgpt' (Chroma wrapper), or 'letta'

  #  =================== LLM Backend Settings ===================

  vad_config:
    vad_model:
    silero_vad:
      orig_sr: 16000
      target_sr: 16000
      prob_threshold: 0.4
      db_threshold: 60
      required_hits: 3
      required_misses: 24
      smoothing_window: 5

  tts_preprocessor_config:
    remove_special_char: true
    ignore_brackets: true
    ignore_parentheses: true
    ignore_asterisks: true
    ignore_angle_brackets: true

    translator_config:
      translate_audio: false
      translate_provider: 'deeplx'

      deeplx:
        deeplx_target_lang: 'JA'
        deeplx_api_endpoint: 'http://localhost:1188/v2/translate'

      tencent:
        secret_id: ''
        secret_key: ''
        region: 'ap-guangzhou'
        source_lang: 'zh'
        target_lang: 'ja'
