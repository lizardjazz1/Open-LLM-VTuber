"""
Centralized translations for Open-LLM-VTuber
This file contains all text strings used in the application.
"""

# Base translations structure
TRANSLATIONS = {
    "en": {
        "app": {
            "name": "Open-LLM-VTuber",
            "description": "Low-latency voice-based LLM interaction tool",
            "version": "Version",
        },
        "server": {
            "starting": "Starting Open-LLM-VTuber server...",
            "started": "Server started successfully",
            "stopping": "Stopping server...",
            "error": "Server error occurred",
            "port_in_use": "Port {port} is already in use",
            "host": "Server host address",
            "port": "Server port number",
            "websocket_connected": "WebSocket client connected",
            "websocket_disconnected": "WebSocket client disconnected",
            "websocket_error": "WebSocket error occurred",
        },
        "config": {
            "loading": "Loading configuration...",
            "loaded": "Configuration loaded successfully",
            "error": "Error loading configuration",
            "not_found": "Configuration file not found",
            "invalid": "Invalid configuration",
            "backup_created": "Configuration backup created",
            "backup_restored": "Configuration backup restored",
            "validation_error": "Configuration validation error",
            "field_required": "Field '{field}' is required",
            "invalid_value": "Invalid value for field '{field}'",
            "conf_version": "Configuration version",
            "host": "Server host address",
            "port": "Server port",
            "language": "Application language",
            "config_alts_dir": "Directory for alternative configurations",
            "config_alt": "Selected alternative configuration",
            "enable_proxy": "Enable proxy mode for live integrations",
            "twitch_config": "Twitch integration settings",
            "tool_prompts": "Utility prompts to append to system prompt",
            "server_label": "Label prefix for server-origin messages in prompts",
            "relationships_db_path": "Path to relationships SQLite database",
            "memory_consolidation_interval_sec": "Memory consolidation interval (seconds)",
            "chroma_persist_dir": "ChromaDB persistent directory",
            "chroma_collection": "ChromaDB collection name (LTM)",
            "embeddings_model": "Embeddings model name",
            "embeddings_api_key": "API key for external embeddings (optional)",
            "embeddings_api_base": "Base URL for external embeddings (optional)",
            "deep_consolidation_every_n_streams": "Deep consolidation cadence (per N streams)",
            "client_log_ingest_enabled": "Enable POST /logs ingestion from frontend",
            "client_log_ingest_require_token": "Require token for /logs (unused in local mode)",
        },
        "llm": {
            "connecting": "Connecting to LLM...",
            "connected": "Connected to LLM",
            "error": "LLM connection error",
            "timeout": "LLM request timeout",
            "generating": "Generating response...",
            "generated": "Response generated",
            "model_loaded": "LLM model loaded successfully",
            "model_error": "Error loading LLM model",
            "context_length": "Context length exceeded",
            "token_limit": "Token limit reached",
            "config.llm.base_url": "Base URL for LLM API",
            "config.llm.llm_api_key": "API key for LLM service",
            "config.llm.organization_id": "Organization ID (optional)",
            "config.llm.project_id": "Project ID (optional)",
            "config.llm.model": "LLM model name",
            "config.llm.temperature": "Temperature for response generation (0.0 to 2.0)",
            "config.llm.top_p": "Top-p sampling parameter",
            "config.llm.frequency_penalty": "Frequency penalty for repetition control",
            "config.llm.presence_penalty": "Presence penalty for topic diversity",
            "config.llm.stop": "Stop sequences to end generation",
            "config.llm.seed": "Random seed for reproducible generation",
            "config.llm.interrupt_method": "Method for handling interruptions",
            "config.llm.lmstudio.llm_api_key": "API key for LM Studio (usually 'default_api_key')",
            "config.llm.lmstudio.base_url": "Base URL for LM Studio API",
            "config.llm.lmstudio.use_harmony": "Use Harmony mode for LM Studio",
            "config.llm.lmstudio.max_tokens": "Maximum tokens for response generation",
            "config.llm.lmstudio.stream": "Enable streaming responses",
            "config.llm.lmstudio.stop_sequences": "Stop sequences to end generation",
            "config.llm.lmstudio.repetition_penalty": "Repetition penalty (1.0 to 2.0)",
            "config.llm.lmstudio.length_penalty": "Length penalty (0.0 to 2.0)",
        },
        "asr": {
            "initializing": "Initializing speech recognition...",
            "ready": "Speech recognition ready",
            "listening": "Listening...",
            "processing": "Processing speech...",
            "error": "Speech recognition error",
            "no_speech": "No speech detected",
            "model_loaded": "ASR model loaded",
            "model_error": "Error loading ASR model",
            "audio_format": "Unsupported audio format",
            "sample_rate": "Invalid sample rate",
        },
        "tts": {
            "initializing": "Initializing text-to-speech...",
            "ready": "Text-to-speech ready",
            "generating": "Generating speech...",
            "generated": "Speech generated",
            "error": "Text-to-speech error",
            "voice_not_found": "Voice not found",
            "model_loaded": "TTS model loaded",
            "model_error": "Error loading TTS model",
            "audio_quality": "Audio quality issue",
            "rate_limit": "TTS rate limit exceeded",
            "ws_open": "TTS WebSocket connection accepted",
            "request": "TTS request received",
            "segment_done": "TTS segment generated",
            "ws_disconnect": "TTS WebSocket disconnected",
            "ws_error": "TTS WebSocket error",
        },
        "vad": {
            "initializing": "Initializing voice activity detection...",
            "ready": "Voice activity detection ready",
            "speech_detected": "Speech detected",
            "silence_detected": "Silence detected",
            "error": "Voice activity detection error",
            "model_loaded": "VAD model loaded",
            "model_error": "Error loading VAD model",
            "threshold_adjusted": "VAD threshold adjusted",
        },
        "live2d": {
            "loading": "Loading Live2D model...",
            "loaded": "Live2D model loaded",
            "error": "Error loading Live2D model",
            "expression_set": "Expression set to {expression}",
            "motion_played": "Motion played: {motion}",
            "model_not_found": "Live2D model not found",
            "parameter_updated": "Parameter updated: {parameter}",
        },
        "proxy": {
            "enabled": "Proxy mode enabled",
            "disabled": "Proxy mode disabled",
            "client_connected": "Proxy client connected",
            "client_disconnected": "Proxy client disconnected",
            "message_forwarded": "Message forwarded to client",
            "error": "Proxy error occurred",
        },
        "twitch": {
            "connecting": "Connecting to Twitch...",
            "connected": "Connected to Twitch",
            "disconnected": "Disconnected from Twitch",
            "error": "Twitch connection error",
            "chat_message": "Chat message received",
            "donation": "Donation received",
            "subscription": "Subscription event",
            "follow": "New follower",
            "raid": "Raid event",
        },
        "memory": {
            "loading": "Loading memory...",
            "loaded": "Memory loaded successfully",
            "saving": "Saving memory...",
            "saved": "Memory saved successfully",
            "error": "Memory error occurred",
            "context_added": "Context added to memory",
            "context_retrieved": "Context retrieved from memory",
            "memory_full": "Memory is full, cleaning old entries",
        },
        "tools": {
            "executing": "Executing tool: {tool}",
            "executed": "Tool executed successfully",
            "error": "Tool execution error",
            "not_found": "Tool not found: {tool}",
            "timeout": "Tool execution timeout",
            "permission_denied": "Tool permission denied",
        },
        "ui": {
            "loading": "Loading...",
            "error": "An error occurred",
            "success": "Operation completed successfully",
            "warning": "Warning",
            "info": "Information",
            "confirm": "Please confirm",
            "cancel": "Cancel",
            "ok": "OK",
            "yes": "Yes",
            "no": "No",
        },
        "validation": {
            "required": "This field is required",
            "invalid_format": "Invalid format",
            "too_short": "Value is too short",
            "too_long": "Value is too long",
            "invalid_range": "Value is out of range",
            "invalid_email": "Invalid email address",
            "invalid_url": "Invalid URL",
        },
        "agent": {
            "initializing": "Initializing agent...",
            "ready": "Agent ready",
            "error": "Agent error",
            "memory_loaded": "Memory loaded",
            "memory_error": "Memory error",
            "conversation_started": "Conversation started",
            "conversation_ended": "Conversation ended",
            "interrupt": "Conversation interrupted",
            "llm_provider_to_use_for_this_agent": "LLM provider to use for this agent",
            "whether_to_respond_as_soon_as_encountering_a_comma_in_the_first_sentence_to_reduce_latency_default_true": "Whether to respond as soon as encountering a comma in the first sentence to reduce latency (default: true)",
            "method_for_segmenting_sentences_regex_or_pysbd_default_pysbd": "Method for segmenting sentences: 'regex' or 'pysbd' (default: pysbd)",
            "whether_to_use_mcp_model_context_protocol_for_the_agent_default_true": "Whether to use MCP (Model Context Protocol) for the agent (default: true)",
            "list_of_mcp_servers_to_enable_for_the_agent": "List of MCP servers to enable for the agent",
            "memory_agent_summarize_max_tokens": "Maximum tokens for memory summarization",
            "memory_agent_summarize_timeout_seconds": "Timeout for memory summarization (seconds)",
            "memory_agent_sentiment_max_tokens": "Maximum tokens for sentiment analysis",
            "memory_agent_sentiment_timeout_seconds": "Timeout for sentiment analysis (seconds)",
            "memory_agent_consolidation_recent_messages_window": "Recent messages window for memory consolidation",
            "enable_stream_mode_for_vtuber_behavior_default_true": "Enable stream mode for VTuber behavior (default: true)",
            "enable_spicy_mode_for_more_sarcastic_responses_default_false": "Enable spicy mode for more sarcastic responses (default: false)",
            "personality_consistency_level_0_0_to_1_0_default_0_8": "Personality consistency level (0.0 to 1.0, default: 0.8)",
            "creativity_level_for_response_generation_0_0_to_1_0_default_0_7": "Creativity level for response generation (0.0 to 1.0, default: 0.7)",
            "emotional_adaptability_level_0_0_to_1_0_default_0_9": "Emotional adaptability level (0.0 to 1.0, default: 0.9)",
        },
    },
    "zh": {
        "app": {
            "name": "Open-LLM-VTuber",
            "description": "低延迟基于语音的LLM交互工具",
            "version": "版本",
        },
        "server": {
            "starting": "正在启动Open-LLM-VTuber服务器...",
            "started": "服务器启动成功",
            "stopping": "正在停止服务器...",
            "error": "服务器发生错误",
            "port_in_use": "端口{port}已被占用",
            "host": "服务器主机地址",
            "port": "服务器端口号",
            "websocket_connected": "WebSocket客户端已连接",
            "websocket_disconnected": "WebSocket客户端已断开",
            "websocket_error": "WebSocket发生错误",
        },
        "config": {
            "loading": "正在加载配置...",
            "loaded": "配置加载成功",
            "error": "加载配置时出错",
            "not_found": "未找到配置文件",
            "invalid": "配置无效",
            "backup_created": "配置备份已创建",
            "backup_restored": "配置备份已恢复",
            "validation_error": "配置验证错误",
            "field_required": "字段'{field}'是必需的",
            "invalid_value": "字段'{field}'的值无效",
            "conf_version": "配置版本",
            "host": "服务器主机地址",
            "port": "服务器端口",
            "language": "应用语言",
            "config_alts_dir": "备用配置目录",
            "config_alt": "选择的备用配置",
            "enable_proxy": "启用直播集成的代理模式",
            "twitch_config": "Twitch 集成设置",
            "tool_prompts": "追加到系统提示的工具提示词",
            "server_label": "用于提示词的服务端消息前缀",
            "relationships_db_path": "关系数据库（SQLite）路径",
            "memory_consolidation_interval_sec": "记忆整合间隔（秒）",
            "chroma_persist_dir": "ChromaDB 持久化目录",
            "chroma_collection": "ChromaDB 集合名（长期记忆）",
            "embeddings_model": "向量嵌入模型名称",
            "embeddings_api_key": "外部嵌入 API 密钥（可选）",
            "embeddings_api_base": "外部嵌入基地址（可选）",
            "deep_consolidation_every_n_streams": "深度整合频率（每 N 次流）",
            "client_log_ingest_enabled": "启用前端日志上报（POST /logs）",
            "client_log_ingest_require_token": "/logs 是否需要令牌（本地模式不使用）",
        },
        "llm": {
            "connecting": "正在连接到LLM...",
            "connected": "已连接到LLM",
            "error": "LLM连接错误",
            "timeout": "LLM请求超时",
            "generating": "正在生成响应...",
            "generated": "响应已生成",
            "model_loaded": "LLM模型加载成功",
            "model_error": "加载LLM模型时出错",
            "context_length": "上下文长度超出限制",
            "token_limit": "达到令牌限制",
            "config.llm.base_url": "LLM API 基础 URL",
            "config.llm.llm_api_key": "LLM 服务 API 密钥",
            "config.llm.organization_id": "组织 ID（可选）",
            "config.llm.project_id": "项目 ID（可选）",
            "config.llm.model": "LLM 模型名称",
            "config.llm.temperature": "响应生成温度（0.0 到 2.0）",
            "config.llm.top_p": "Top-p 采样参数",
            "config.llm.frequency_penalty": "重复控制频率惩罚",
            "config.llm.presence_penalty": "主题多样性存在惩罚",
            "config.llm.stop": "生成结束停止序列",
            "config.llm.seed": "可重复生成随机种子",
            "config.llm.interrupt_method": "中断处理方法",
            "config.llm.lmstudio.llm_api_key": "LM Studio API 密钥（通常为 'default_api_key'）",
            "config.llm.lmstudio.base_url": "LM Studio API 基础 URL",
            "config.llm.lmstudio.use_harmony": "使用 Harmony 模式进行 LM Studio",
            "config.llm.lmstudio.max_tokens": "响应生成最大令牌数",
            "config.llm.lmstudio.stream": "启用流式响应",
            "config.llm.lmstudio.stop_sequences": "生成结束停止序列",
            "config.llm.lmstudio.repetition_penalty": "重复惩罚（1.0 到 2.0）",
            "config.llm.lmstudio.length_penalty": "长度惩罚（0.0 到 2.0）",
        },
        "asr": {
            "initializing": "正在初始化语音识别...",
            "ready": "语音识别已就绪",
            "listening": "正在监听...",
            "processing": "正在处理语音...",
            "error": "语音识别错误",
            "no_speech": "未检测到语音",
            "model_loaded": "ASR模型已加载",
            "model_error": "加载ASR模型时出错",
            "audio_format": "不支持的音频格式",
            "sample_rate": "无效的采样率",
        },
        "tts": {
            "initializing": "正在初始化文本转语音...",
            "ready": "文本转语音已就绪",
            "generating": "正在生成语音...",
            "generated": "语音已生成",
            "error": "文本转语音错误",
            "voice_not_found": "未找到语音",
            "model_loaded": "TTS模型已加载",
            "model_error": "加载TTS模型时出错",
            "audio_quality": "音频质量问题",
            "rate_limit": "TTS速率限制超出",
            "ws_open": "TTS WebSocket 连接已接受",
            "request": "收到 TTS 请求",
            "segment_done": "TTS 片段已生成",
            "ws_disconnect": "TTS WebSocket 已断开",
            "ws_error": "TTS WebSocket 错误",
        },
        "vad": {
            "initializing": "正在初始化语音活动检测...",
            "ready": "语音活动检测已就绪",
            "speech_detected": "检测到语音",
            "silence_detected": "检测到静音",
            "error": "语音活动检测错误",
            "model_loaded": "VAD模型已加载",
            "model_error": "加载VAD模型时出错",
            "threshold_adjusted": "VAD阈值已调整",
        },
        "live2d": {
            "loading": "正在加载Live2D模型...",
            "loaded": "Live2D模型已加载",
            "error": "加载Live2D模型时出错",
            "expression_set": "表情设置为{expression}",
            "motion_played": "播放动作：{motion}",
            "model_not_found": "未找到Live2D模型",
            "parameter_updated": "参数已更新：{parameter}",
        },
        "proxy": {
            "enabled": "代理模式已启用",
            "disabled": "代理模式已禁用",
            "client_connected": "代理客户端已连接",
            "client_disconnected": "代理客户端已断开",
            "message_forwarded": "消息已转发给客户端",
            "error": "代理发生错误",
        },
        "twitch": {
            "connecting": "正在连接到Twitch...",
            "connected": "已连接到Twitch",
            "disconnected": "已断开与Twitch的连接",
            "error": "Twitch连接错误",
            "chat_message": "收到聊天消息",
            "donation": "收到捐赠",
            "subscription": "订阅事件",
            "follow": "新关注者",
            "raid": "突袭事件",
        },
        "memory": {
            "loading": "正在加载内存...",
            "loaded": "内存加载成功",
            "saving": "正在保存内存...",
            "saved": "内存保存成功",
            "error": "内存错误",
            "context_added": "上下文已添加到内存",
            "context_retrieved": "从内存中检索到上下文",
            "memory_full": "内存已满，正在清理旧条目",
        },
        "tools": {
            "executing": "正在执行工具：{tool}",
            "executed": "工具执行成功",
            "error": "工具执行错误",
            "not_found": "未找到工具：{tool}",
            "timeout": "工具执行超时",
            "permission_denied": "工具权限被拒绝",
        },
        "ui": {
            "loading": "正在加载...",
            "error": "发生错误",
            "success": "操作成功完成",
            "warning": "警告",
            "info": "信息",
            "confirm": "请确认",
            "cancel": "取消",
            "ok": "确定",
            "yes": "是",
            "no": "否",
        },
        "validation": {
            "required": "此字段是必需的",
            "invalid_format": "格式无效",
            "too_short": "值太短",
            "too_long": "值太长",
            "invalid_range": "值超出范围",
            "invalid_email": "无效的电子邮件地址",
            "invalid_url": "无效的URL",
        },
        "agent": {
            "initializing": "正在初始化代理...",
            "ready": "代理已就绪",
            "error": "代理发生错误",
            "memory_loaded": "记忆已加载",
            "memory_error": "记忆错误",
            "conversation_started": "对话已开始",
            "conversation_ended": "对话已结束",
            "interrupt": "对话已中断",
            "llm_provider_to_use_for_this_agent": "此代理使用的LLM提供商",
            "whether_to_respond_as_soon_as_encountering_a_comma_in_the_first_sentence_to_reduce_latency_default_true": "是否在遇到第一个句子中的逗号时立即响应以减少延迟（默认：是）",
            "method_for_segmenting_sentences_regex_or_pysbd_default_pysbd": "句子分割方法：'regex' 或 'pysbd'（默认：pysbd）",
            "whether_to_use_mcp_model_context_protocol_for_the_agent_default_true": "是否为代理使用 MCP（模型上下文协议）（默认：是）",
            "list_of_mcp_servers_to_enable_for_the_agent": "为代理启用 MCP 服务器的列表",
            "memory_agent_summarize_max_tokens": "记忆摘要最大令牌数",
            "memory_agent_summarize_timeout_seconds": "记忆摘要超时（秒）",
            "memory_agent_sentiment_max_tokens": "情感分析最大令牌数",
            "memory_agent_sentiment_timeout_seconds": "情感分析超时（秒）",
            "memory_agent_consolidation_recent_messages_window": "记忆整合最近消息窗口",
            "enable_stream_mode_for_vtuber_behavior_default_true": "启用 VTuber 行为流式模式（默认：是）",
            "enable_spicy_mode_for_more_sarcastic_responses_default_false": "启用更讽刺的响应（默认：否）",
            "personality_consistency_level_0_0_to_1_0_default_0_8": "个性一致性水平（0.0 到 1.0，默认：0.8）",
            "creativity_level_for_response_generation_0_0_to_1_0_default_0_7": "响应生成创造力水平（0.0 到 1.0，默认：0.7）",
            "emotional_adaptability_level_0_0_to_1_0_default_0_9": "情感适应性水平（0.0 到 1.0，默认：0.9）",
        },
    },
    "ru": {
        "app": {
            "name": "Open-LLM-VTuber",
            "description": "Инструмент голосового взаимодействия с LLM с низкой задержкой",
            "version": "Версия",
        },
        "server": {
            "starting": "Запуск сервера Open-LLM-VTuber...",
            "started": "Сервер успешно запущен",
            "stopping": "Остановка сервера...",
            "error": "Произошла ошибка сервера",
            "port_in_use": "Порт {port} уже используется",
            "host": "Адрес хоста сервера",
            "port": "Номер порта сервера",
            "websocket_connected": "WebSocket клиент подключен",
            "websocket_disconnected": "WebSocket клиент отключен",
            "websocket_error": "Ошибка WebSocket",
        },
        "config": {
            "loading": "Загрузка конфигурации...",
            "loaded": "Конфигурация успешно загружена",
            "error": "Ошибка загрузки конфигурации",
            "not_found": "Файл конфигурации не найден",
            "invalid": "Недействительная конфигурация",
            "backup_created": "Резервная копия конфигурации создана",
            "backup_restored": "Резервная копия конфигурации восстановлена",
            "validation_error": "Ошибка валидации конфигурации",
            "field_required": "Поле '{field}' обязательно",
            "invalid_value": "Недействительное значение для поля '{field}'",
            "conf_version": "Версия конфигурации",
            "host": "Адрес хоста сервера",
            "port": "Порт сервера",
            "language": "Язык приложения",
            "config_alts_dir": "Каталог альтернативных конфигураций",
            "config_alt": "Выбранная альтернативная конфигурация",
            "enable_proxy": "Включить прокси-режим для интеграций",
            "twitch_config": "Настройки интеграции Twitch",
            "tool_prompts": "Утил‑промпты для добавления в системный промпт",
            "server_label": "Префикс для серверных сообщений в промптах",
            "relationships_db_path": "Путь к базе отношений (SQLite)",
            "memory_consolidation_interval_sec": "Интервал консолидации памяти (сек)",
            "chroma_persist_dir": "Каталог данных ChromaDB",
            "chroma_collection": "Имя коллекции ChromaDB (LTM)",
            "embeddings_model": "Модель эмбеддингов",
            "embeddings_api_key": "API‑ключ внешних эмбеддингов (опц.)",
            "embeddings_api_base": "Базовый URL внешних эмбеддингов (опц.)",
            "deep_consolidation_every_n_streams": "Период глубокой консолидации (на N стримов)",
            "client_log_ingest_enabled": "Включить приём логов от фронта (POST /logs)",
            "client_log_ingest_require_token": "Требовать токен для /logs (в локальном режиме не используется)",
        },
        "llm": {
            "connecting": "Подключение к LLM...",
            "connected": "Подключено к LLM",
            "error": "Ошибка подключения к LLM",
            "timeout": "Таймаут запроса LLM",
            "generating": "Генерация ответа...",
            "generated": "Ответ сгенерирован",
            "model_loaded": "Модель LLM загружена успешно",
            "model_error": "Ошибка загрузки модели LLM",
            "context_length": "Превышена длина контекста",
            "token_limit": "Достигнут лимит токенов",
            "config.llm.base_url": "Базовый URL API LLM",
            "config.llm.llm_api_key": "API ключ сервиса LLM",
            "config.llm.organization_id": "Идентификатор организации (опц.)",
            "config.llm.project_id": "Идентификатор проекта (опц.)",
            "config.llm.model": "Название модели LLM",
            "config.llm.temperature": "Температура для генерации ответа (0.0 до 2.0)",
            "config.llm.top_p": "Параметр Top-p для выборки",
            "config.llm.frequency_penalty": "Штраф за частоту для контроля повторений",
            "config.llm.presence_penalty": "Штраф за присутствие для разнообразия темы",
            "config.llm.stop": "Последовательности для завершения генерации",
            "config.llm.seed": "Семя для воспроизводимой генерации",
            "config.llm.interrupt_method": "Метод обработки прерываний",
            "config.llm.lmstudio.llm_api_key": "API ключ LM Studio (обычно 'default_api_key')",
            "config.llm.lmstudio.base_url": "Базовый URL API LM Studio",
            "config.llm.lmstudio.use_harmony": "Использовать гармонию для LM Studio",
            "config.llm.lmstudio.max_tokens": "Максимальное количество токенов для генерации ответа",
            "config.llm.lmstudio.stream": "Включить потоковые ответы",
            "config.llm.lmstudio.stop_sequences": "Последовательности для завершения генерации",
            "config.llm.lmstudio.repetition_penalty": "Штраф за повторение (1.0 до 2.0)",
            "config.llm.lmstudio.length_penalty": "Штраф за длину (0.0 до 2.0)",
        },
        "asr": {
            "initializing": "Инициализация распознавания речи...",
            "ready": "Распознавание речи готово",
            "listening": "Прослушивание...",
            "processing": "Обработка речи...",
            "error": "Ошибка распознавания речи",
            "no_speech": "Речь не обнаружена",
            "model_loaded": "Модель ASR загружена",
            "model_error": "Ошибка загрузки модели ASR",
            "audio_format": "Неподдерживаемый формат аудио",
            "sample_rate": "Недействительная частота дискретизации",
        },
        "tts": {
            "initializing": "Инициализация преобразования текста в речь...",
            "ready": "Преобразование текста в речь готово",
            "generating": "Генерация речи...",
            "generated": "Речь сгенерирована",
            "error": "Ошибка преобразования текста в речь",
            "voice_not_found": "Голос не найден",
            "model_loaded": "Модель TTS загружена",
            "model_error": "Ошибка загрузки модели TTS",
            "audio_quality": "Проблема качества аудио",
            "rate_limit": "Превышен лимит скорости TTS",
            "ws_open": "Подключение TTS WebSocket принято",
            "request": "Получен запрос TTS",
            "segment_done": "Сгенерирован TTS‑сегмент",
            "ws_disconnect": "TTS WebSocket отключен",
            "ws_error": "Ошибка TTS WebSocket",
        },
        "vad": {
            "initializing": "Инициализация обнаружения речевой активности...",
            "ready": "Обнаружение речевой активности готово",
            "speech_detected": "Обнаружена речь",
            "silence_detected": "Обнаружена тишина",
            "error": "Ошибка обнаружения речевой активности",
            "model_loaded": "Модель VAD загружена",
            "model_error": "Ошибка загрузки модели VAD",
            "threshold_adjusted": "Порог VAD скорректирован",
        },
        "live2d": {
            "loading": "Загрузка модели Live2D...",
            "loaded": "Модель Live2D загружена",
            "error": "Ошибка загрузки модели Live2D",
            "expression_set": "Выражение установлено: {expression}",
            "motion_played": "Воспроизведено движение: {motion}",
            "model_not_found": "Модель Live2D не найдена",
            "parameter_updated": "Параметр обновлен: {parameter}",
        },
        "proxy": {
            "enabled": "Режим прокси включен",
            "disabled": "Режим прокси отключен",
            "client_connected": "Прокси клиент подключен",
            "client_disconnected": "Прокси клиент отключен",
            "message_forwarded": "Сообщение переслано клиенту",
            "error": "Произошла ошибка прокси",
        },
        "twitch": {
            "connecting": "Подключение к Twitch...",
            "connected": "Подключено к Twitch",
            "disconnected": "Отключено от Twitch",
            "error": "Ошибка подключения к Twitch",
            "chat_message": "Получено сообщение чата",
            "donation": "Получено пожертвование",
            "subscription": "Событие подписки",
            "follow": "Новый подписчик",
            "raid": "Событие рейда",
        },
        "memory": {
            "loading": "Загрузка памяти...",
            "loaded": "Память успешно загружена",
            "saving": "Сохранение памяти...",
            "saved": "Память успешно сохранена",
            "error": "Ошибка памяти",
            "context_added": "Контекст добавлен в память",
            "context_retrieved": "Контекст извлечен из памяти",
            "memory_full": "Память заполнена, очистка старых записей",
        },
        "tools": {
            "executing": "Выполнение инструмента: {tool}",
            "executed": "Инструмент выполнен успешно",
            "error": "Ошибка выполнения инструмента",
            "not_found": "Инструмент не найден: {tool}",
            "timeout": "Таймаут выполнения инструмента",
            "permission_denied": "Доступ к инструменту запрещен",
        },
        "ui": {
            "loading": "Загрузка...",
            "error": "Произошла ошибка",
            "success": "Операция успешно завершена",
            "warning": "Предупреждение",
            "info": "Информация",
            "confirm": "Пожалуйста, подтвердите",
            "cancel": "Отмена",
            "ok": "ОК",
            "yes": "Да",
            "no": "Нет",
        },
        "validation": {
            "required": "Это поле обязательно",
            "invalid_format": "Недействительный формат",
            "too_short": "Значение слишком короткое",
            "too_long": "Значение слишком длинное",
            "invalid_range": "Значение вне диапазона",
            "invalid_email": "Недействительный адрес электронной почты",
            "invalid_url": "Недействительный URL",
        },
        "agent": {
            "initializing": "Инициализация агента...",
            "ready": "Агент готов",
            "error": "Ошибка агента",
            "memory_loaded": "Память загружена",
            "memory_error": "Ошибка памяти",
            "conversation_started": "Диалог начат",
            "conversation_ended": "Диалог завершен",
            "interrupt": "Диалог прерван",
            "llm_provider_to_use_for_this_agent": "LLM-провайдер для этого агента",
            "whether_to_respond_as_soon_as_encountering_a_comma_in_the_first_sentence_to_reduce_latency_default_true": "Отвечать сразу, когда встречается запятая в первом предложении, чтобы уменьшить задержку (по умолчанию: да)",
            "method_for_segmenting_sentences_regex_or_pysbd_default_pysbd": "Метод сегментации предложений: 'regex' или 'pysbd' (по умолчанию: pysbd)",
            "whether_to_use_mcp_model_context_protocol_for_the_agent_default_true": "Использовать MCP (Model Context Protocol) для агента (по умолчанию: да)",
            "list_of_mcp_servers_to_enable_for_the_agent": "Список MCP-серверов для включения",
            "memory_agent_summarize_max_tokens": "Максимальное количество токенов для краткой памяти",
            "memory_agent_summarize_timeout_seconds": "Таймаут краткой памяти (секунды)",
            "memory_agent_sentiment_max_tokens": "Максимальное количество токенов для анализа эмоций",
            "memory_agent_sentiment_timeout_seconds": "Таймаут анализа эмоций (секунды)",
            "memory_agent_consolidation_recent_messages_window": "Окно последних сообщений для консолидации памяти",
            "enable_stream_mode_for_vtuber_behavior_default_true": "Включить поток для поведения VTuber (по умолчанию: да)",
            "enable_spicy_mode_for_more_sarcastic_responses_default_false": "Включить более циничные ответы (по умолчанию: нет)",
            "personality_consistency_level_0_0_to_1_0_default_0_8": "Уровень последовательности личности (0.0 до 1.0, по умолчанию: 0.8)",
            "creativity_level_for_response_generation_0_0_to_1_0_default_0_7": "Уровень креативности для генерации ответа (0.0 до 1.0, по умолчанию: 0.7)",
            "emotional_adaptability_level_0_0_to_1_0_default_0_9": "Уровень эмоциональной адаптации (0.0 до 1.0, по умолчанию: 0.9)",
        },
    },
}


def get_translation(key: str, lang_code: str = "en") -> str:
    """
    Get a translation by key and language code.

    Args:
        key: Translation key (e.g., "server.starting")
        lang_code: Language code (e.g., "en", "zh", "ru")

    Returns:
        Translated text or the key itself if not found
    """
    if lang_code not in TRANSLATIONS:
        lang_code = "en"

    # Split key by dots to navigate nested structure
    keys = key.split(".")
    translation = TRANSLATIONS[lang_code]

    # Navigate through nested structure
    for k in keys:
        if isinstance(translation, dict) and k in translation:
            translation = translation[k]
        else:
            # Key not found, fallback to English
            if lang_code != "en":
                return get_translation(key, "en")
            return key

    # If we found a string, return it
    if isinstance(translation, str):
        return translation

    # Fallback to English
    if lang_code != "en":
        return get_translation(key, "en")

    return key


def get_available_languages() -> list[str]:
    """
    Get list of available language codes.

    Returns:
        List of available language codes
    """
    return list(TRANSLATIONS.keys())


def format_translation(key: str, lang_code: str = "en", **kwargs) -> str:
    """
    Get a formatted translation with placeholders.

    Args:
        key: Translation key
        lang_code: Language code
        **kwargs: Format arguments

    Returns:
        Formatted translated text
    """
    translation = get_translation(key, lang_code)

    try:
        return translation.format(**kwargs)
    except (KeyError, ValueError):
        # If formatting fails, return the translation as is
        return translation
